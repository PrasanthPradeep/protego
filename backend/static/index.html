<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>ü¶∫ Construction PPE Safety ‚Äì Live Monitor</title>

  <style>
    body {
      margin: 0;
      background: #0b0b0b;
      color: #fff;
      font-family: Arial, sans-serif;
      text-align: center;
    }

    h2 { margin: 12px; }

    video, canvas {
      width: 640px;
      border: 2px solid #00ff6a;
      margin-top: 10px;
    }

    #status {
      margin-top: 6px;
      font-size: 14px;
      color: #00ff6a;
    }

    #log-panel {
      width: 640px;
      height: 180px;
      margin: 12px auto;
      padding: 10px;
      border: 1px solid #444;
      background: #111;
      overflow-y: auto;
      font-family: monospace;
      color: #ff4c4c;
      text-align: left;
    }

    button {
      margin: 6px;
      padding: 6px 14px;
      background: #222;
      color: #fff;
      border: 1px solid #555;
      cursor: pointer;
    }

    button:hover { background: #333; }
  </style>
</head>

<body>

<h2>ü¶∫ Construction PPE Safety ‚Äì Live Monitor</h2>

<video id="video" autoplay playsinline></video>
<canvas id="canvas" width="640" height="480" hidden></canvas>
<canvas id="output" width="640" height="480"></canvas>

<div id="status">Initializing‚Ä¶</div>
<div id="log-panel"></div>

<button onclick="toggleAudio()">üîä Toggle Audio</button>

<script>
/* ================= AUDIO ENGINE ================= */
let audioEnabled = true;
let speaking = false;
const queue = [];
const lastSpoken = {};
const COOLDOWN = 5000;
let voices = [];

speechSynthesis.onvoiceschanged = () => {
  voices = speechSynthesis.getVoices();
};

function enqueue(type, msg) {
  if (!audioEnabled) return;

  const now = Date.now();
  if (lastSpoken[type] && now - lastSpoken[type] < COOLDOWN) return;

  lastSpoken[type] = now;
  queue.push(msg);
  playNext();
}

function playNext() {
  if (speaking || queue.length === 0) return;

  speaking = true;
  const text = queue.shift();
  const u = new SpeechSynthesisUtterance(text);

  const en = voices.find(v => v.lang.startsWith("en"));
  if (en) u.voice = en;

  u.rate = 1.05;
  u.onend = () => {
    speaking = false;
    playNext();
  };

  speechSynthesis.speak(u);
}

function toggleAudio() {
  audioEnabled = !audioEnabled;
  speechSynthesis.cancel();
  queue.length = 0;
  speaking = false;
}

/* ================= VIDEO + WS ================= */
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const output = document.getElementById("output");
const ctx = canvas.getContext("2d");
const out = output.getContext("2d");
const status = document.getElementById("status");
const logPanel = document.getElementById("log-panel");

const ws = new WebSocket(
  (location.protocol === "https:" ? "wss://" : "ws://") +
  location.host +
  "/ws/safety"
);

ws.onopen = () => status.textContent = "‚úÖ Connected";
ws.onerror = () => status.textContent = "‚ùå WebSocket error";

ws.onmessage = e => {
  const d = JSON.parse(e.data);

  logPanel.innerHTML = "";
  d.logs?.slice().reverse().forEach(l => {
    logPanel.innerHTML += `[${l.time}] ${l.type}<br>`;
  });

  d.violations?.forEach(v => {
    if (v.type === "NO_HARDHAT") enqueue(v.type, "Warning. Hard hat missing.");
    if (v.type === "NO_MASK") enqueue(v.type, "Warning. Safety mask missing.");
    if (v.type === "NO_SAFETY_VEST") enqueue(v.type, "Warning. Safety vest missing.");
  });

  if (d.frame) {
    const img = new Image();
    img.onload = () => out.drawImage(img, 0, 0, 640, 480);
    img.src = "data:image/jpeg;base64," + d.frame;
  }
};

/* ================= CAMERA ================= */
navigator.mediaDevices.getUserMedia({ video: true })
  .then(stream => {
    video.srcObject = stream;
    status.textContent = "üì∑ Camera started";

    setInterval(() => {
      ctx.drawImage(video, 0, 0, 640, 480);
      ws.send(canvas.toDataURL("image/jpeg", 0.7));
    }, 200);
  })
  .catch(() => status.textContent = "‚ùå Camera access denied");
</script>

</body>
</html>
